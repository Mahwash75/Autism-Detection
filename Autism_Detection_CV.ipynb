{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 930,
     "referenced_widgets": [
      "28eed00087284d3f8b987239b38629cc",
      "1e927cc34d744940a90a26e77e94768b",
      "ff2330dc3202420daf01c83feae005ee",
      "59324cf15010477b9158de81576113bb",
      "6feb57d6bb4e4ab7a599504857af7f9c",
      "8cadd34a87cb41a1ac62b5c4323d28de",
      "3ebb725b398b4eb4b20b5fd1204cfa6d",
      "fc55c0ccef8e4533a4c2e918ff96c534",
      "daa5fdecc5994620b02fdd4fa9cdd251",
      "3814075159474113a85f6defaaae59bd",
      "f2c6db2fca03472ebe1ba3201a69ad54",
      "17c3819d403544ee9f023fb70cce2c52",
      "54c4a36add0741bda3ed796c56965539",
      "bd397c003ac344159405d683b548c28d",
      "dc665be558b54ab08939fc8bfdc14399",
      "d08c416f3ea2443582a53afd1ab0c41a",
      "fc99350ae90d4c0786244d0697bc333c",
      "607d96d1bef146c9b3f59155d86bfc43",
      "da1d180e3fd842e9a4a8dad2929c8259",
      "04d72317d18241018569279432782b8e",
      "9608fddfb6f24479ad7f9376eee7f2fd",
      "5cb97ffd16b04bff9cccbd5c0bf4db42",
      "6169cf955d7848ad8b3dce818119d1f8",
      "60740652b1244251b75af5ebf1286ab7",
      "c2608477028e4985af5b80a717ee0db3",
      "eb521e77ee5c4b479844072fdd3a44b1",
      "a7a0729d4f3a49488a33287a9032e7ff",
      "0733591a2c314f579b46a0427a260cec",
      "934917af3aba46af953c4758e978e55d",
      "a6a68f152c474084b69bc1f94d714764",
      "4b3bce362ce244e7a35eccca93f3c295",
      "2d08a17f94e64932b9225de964e03124",
      "d59d0d4f26754a3dba66bc732f7c9320",
      "63782ef7f011456fbf697dcee21abee3",
      "859356d47c9945e4b423996672cb313c",
      "e259793403f544069bd1ed11f0815f6f",
      "5b81212dc0774c409da6785f2970c2d0",
      "05d04b5fc2a34599bc5f3bf437938228",
      "f5f69886c849491fb6832f5579962cc3",
      "840dd3ece9484020b74ce27b897114a0",
      "7fd4445c3bf94c608cb13ecbf6c7ea09",
      "ed449b2d59004c838c7ee00b65934634",
      "1930e35e790d4f10843c727330dc9c30",
      "981dcce75efa4900a6a965e69da7132a",
      "ae45a9a2b6be4425b5df7de3178ce673",
      "f39fd887c2db4ac48378255ae974cbb2",
      "779fd910cdbb40dcb042fc327d9d79de",
      "7fb5a5c76eba43f1bfb26686ebe7a338",
      "a5969d139d6c4a0896457d948e612144",
      "338331c926ed48f1b377ef2cf7d447f1",
      "bea802fd28e546689e38e8042f7bee12",
      "c65d6bb0955042ac9e42c9f7c4d210d4",
      "42ff2a065e5e490daf8e83fad7f7255c",
      "ff2d8850bc4342fdb1f1a57f5eeeb6e3",
      "f8a5bb9bb4aa4fb2bc64d249138b2263",
      "e8c8a079a28e43a3bfd0d3471f9949ae",
      "f9a7d851e39b461ca1dde4e8f65adc00",
      "ce1132c67e1744e89216f5004e9a7b45",
      "3f84b0fb540442bfa9b459dea9963c6e",
      "f3368fa2c05b45ecbf2f01de714b7a97",
      "818d40a00ece414baa7ba34a71c36c30",
      "3e49977f3bb94aae82f11daeaf46365d",
      "d5bd6c6478d6495985427ca88de49d0c",
      "f89021e0388041ae8c3f8f21609e6be8",
      "9100b346e7034af0b18dfc9451269c37",
      "a4316bfc788348e8ba60b335117f6dc4",
      "409404cd4c7a416aabc2f1d57e9a588b",
      "ddb8c2a0276c45e6a2d787bd2d8d5d18",
      "5b60112890974a998ffcc05f2739f2b3",
      "b08d729499f64dcf8dc541e5982b31dd",
      "2e203b50aeeb401d8fb7f6c07ca5fbcc",
      "54e59cee4d4c4a11b710ddfd2fe154bd",
      "ac7653958c974885b8895f16524e850e",
      "3bed1443dfb14cca896d2ee49525b82b",
      "0a69f47d418249f783a0b168eb6c6d2a",
      "c0e46fedbd8a44a3aad263c0140bd55d",
      "4aa47ed1e54448e5992e1c31f26c7462",
      "25b0bf869f614b708064e8d57dcc7f3a",
      "819e315e87f34730b0fa982720d50c3f",
      "ac5a9fe6a54f495494e7c498c10b5c1e",
      "44aac23a49374d0ea62dc3e8491e86e5",
      "68cf9c0be5d6466db296eb782b1037f5",
      "94596be881784ef8a73bca48b3c45bdc",
      "a61bf702ae334795ae0584a70f73012f",
      "31593c5680e34b4bb13e495da3f43b65",
      "23ac123a312a4448a6d346b7432742f7",
      "270826047da448fd8e36862118ccfde5",
      "8c6334c0d3304e738530399d6a7131e6",
      "e94ac27070da4c7b9f981669b124f970",
      "2d1dbb32ffe64e32aa52fc89e9e2a3b7",
      "bf9e6c49abc1465dbb3ddf8196e654b2",
      "8fa9ee723c5740ed8f9b215d8d42afb6",
      "56756fd294b1414f92ed9ab435a690b0",
      "005d89da348a4cb4a2ac6217f6a5ab4f",
      "4ffcd35cf04542f7a8f3c6f87e7832b1",
      "6f28595858504c6c96e31f8f89df970c",
      "7935ac5e1f8b401dbcb47a03b32bba36",
      "d08c50276c744b50a7ed2e75ac83cdf7",
      "ae62a3ccc64d448eb9928483d88872ef",
      "a11bde221f744b818c5952e07641ea0a",
      "8453e1067ed448e39b844c0949d7639a",
      "43eb1708de014b10aadb29d669d304e7",
      "a633e9c2c92e433686e02802ae0c3e2c",
      "624c280f2bbc47efb488e10978c7ec95",
      "3b3b1c1349d1411283fe924e62a74954",
      "e95ee9b060334916a40f99115b383e77",
      "45012470611a46939e425795402404dc",
      "4029686727f649c784e63237b3619d96",
      "ebb37eb3891948a186cc8d23905ec832",
      "a7ffb2760d1441dba8fd82f26691db59"
     ]
    },
    "id": "FQ6UcMjxrIyJ",
    "outputId": "c057fd1a-cb27-45ae-94c0-8dc768c9f8e5"
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28eed00087284d3f8b987239b38629cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/502 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17c3819d403544ee9f023fb70cce2c52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "INFO:pytorch_lightning.callbacks.model_summary:\n",
      "  | Name      | Type             | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | model     | AutismClassifier | 85.8 M | train\n",
      "1 | criterion | CrossEntropyLoss | 0      | train\n",
      "-------------------------------------------------------\n",
      "1.5 K     Trainable params\n",
      "85.8 M    Non-trainable params\n",
      "85.8 M    Total params\n",
      "343.201   Total estimated model params size (MB)\n",
      "3         Modules in train mode\n",
      "225       Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6169cf955d7848ad8b3dce818119d1f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63782ef7f011456fbf697dcee21abee3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae45a9a2b6be4425b5df7de3178ce673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8c8a079a28e43a3bfd0d3471f9949ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "409404cd4c7a416aabc2f1d57e9a588b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25b0bf869f614b708064e8d57dcc7f3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e94ac27070da4c7b9f981669b124f970",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=5` reached.\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a11bde221f744b818c5952e07641ea0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6601941585540771     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6611233949661255     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6601941585540771    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6611233949661255    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: No_Autism\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sat Nov 23 12:22:20 2024\n",
    "\n",
    "@author: Mahwash Shakoor\n",
    "\n",
    "Autism Detection\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import ViTForImageClassification\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from torchmetrics.functional import accuracy\n",
    "from pytorch_lightning.loggers import TensorBoardLogger, WandbLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "\n",
    "# Define image transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # ViT input size\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])  # Normalize to [-1, 1]\n",
    "])\n",
    "\n",
    "# Load datasets\n",
    "data_dir = \"/content/drive/MyDrive/Data_9B\"\n",
    "train_dataset = datasets.ImageFolder(os.path.join(data_dir, \"train\"), transform=transform)\n",
    "val_dataset = datasets.ImageFolder(os.path.join(data_dir, \"val\"), transform=transform)\n",
    "test_dataset = datasets.ImageFolder(os.path.join(data_dir, \"test\"), transform=transform)\n",
    "\n",
    "# Data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "# Vit Transformer Model Defination\n",
    "\n",
    "# Load pre-trained ViT and modify for binary classification\n",
    "class AutismClassifier(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(AutismClassifier, self).__init__()\n",
    "    self.vit = ViTForImageClassification.from_pretrained(\n",
    "        \"google/vit-base-patch16-224-in21k\", num_labels=2)  # Binary classification\n",
    "\n",
    "    # Freeze pre-trained layers (except the final classifier)\n",
    "    for param in self.vit.parameters():\n",
    "      param.requires_grad = False  # Freeze all parameters except the last layer\n",
    "\n",
    "    # Modify the final classifier\n",
    "    self.vit.classifier = nn.Linear(self.vit.classifier.in_features, 2)\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.vit(x).logits\n",
    "\n",
    "\n",
    "# Pytorch Modeule\n",
    "\n",
    "from torchmetrics.functional import accuracy\n",
    "\n",
    "class AutismClassifierLit(pl.LightningModule):\n",
    "    def __init__(self, learning_rate=2e-5):\n",
    "        super(AutismClassifierLit, self).__init__()\n",
    "        self.model = AutismClassifier()\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "      images, labels = batch\n",
    "      logits = self(images)\n",
    "      loss = self.criterion(logits, labels)\n",
    "\n",
    "      # Convert logits to predicted classes\n",
    "      preds = torch.argmax(logits, dim=1)\n",
    "      acc = accuracy(preds, labels, task=\"binary\")\n",
    "\n",
    "      self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "      self.log(\"train_acc\", acc, on_step=True, on_epoch=True, prog_bar=True)\n",
    "      return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "      images, labels = batch\n",
    "      logits = self(images)\n",
    "      loss = self.criterion(logits, labels)\n",
    "\n",
    "      # Convert logits to predicted classes\n",
    "      preds = torch.argmax(logits, dim=1)\n",
    "      acc = accuracy(preds, labels, task=\"binary\")\n",
    "\n",
    "      self.log(\"val_loss\", loss, on_epoch=True, prog_bar=True)\n",
    "      self.log(\"val_acc\", acc, on_epoch=True, prog_bar=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "      images, labels = batch\n",
    "      logits = self(images)\n",
    "      loss = self.criterion(logits, labels)\n",
    "\n",
    "      # Convert logits to predicted classes\n",
    "      preds = torch.argmax(logits, dim=1)\n",
    "      acc = accuracy(preds, labels, task=\"binary\")\n",
    "\n",
    "      self.log(\"test_loss\", loss, prog_bar=True)\n",
    "      self.log(\"test_acc\", acc, prog_bar=True)\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(), lr=self.learning_rate)\n",
    "\n",
    "\n",
    "# Choose a logger (TensorBoard or WandB)\n",
    "logger = TensorBoardLogger(\"logs\", name=\"Autism_Classifier\")\n",
    "# logger = WandbLogger(project=\"Autism_Classifier\")\n",
    "\n",
    "# Model checkpointing\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"val_loss\",\n",
    "    dirpath=\"checkpoints/\",\n",
    "    filename=\"best-checkpoint\",\n",
    "    save_top_k=1,\n",
    "    mode=\"min\",\n",
    ")\n",
    "\n",
    "# Instantiate the model\n",
    "model = AutismClassifierLit()\n",
    "\n",
    "# Trainer\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=5,\n",
    "    devices=1,\n",
    "    logger=logger,\n",
    "    callbacks=[checkpoint_callback],\n",
    "    log_every_n_steps=10\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "\n",
    "# Evalute the Model on the test set\n",
    "\n",
    "# Load the best checkpoint\n",
    "best_model_path = checkpoint_callback.best_model_path\n",
    "model = AutismClassifierLit.load_from_checkpoint(best_model_path)\n",
    "\n",
    "# Test the model\n",
    "trainer.test(model, test_loader)\n",
    "\n",
    "#inference\n",
    "\n",
    "\n",
    "\n",
    "def predict_image(image_path, model, transform):\n",
    "    model.eval()\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "    logits = model(image)\n",
    "    pred = torch.argmax(logits, dim=1).item()\n",
    "    class_map = {0: \"Autism\", 1: \"No_Autism\"}\n",
    "    return class_map[pred]\n",
    "\n",
    "# Example inference\n",
    "image_path = \"/content/drive/MyDrive/Data_9B/test/autistic/001.jpg\"\n",
    "prediction = predict_image(image_path, model.model, transform)\n",
    "print(f\"Prediction: {prediction}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QAfuQ40fLDzS",
    "outputId": "e6cfd853-14c8-4713-fa8d-7b5befda7113"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch_lightning\n",
      "  Downloading pytorch_lightning-2.4.0-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (2.5.1+cu121)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (4.66.6)\n",
      "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (6.0.2)\n",
      "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (2024.10.0)\n",
      "Collecting torchmetrics>=0.7.0 (from pytorch_lightning)\n",
      "  Downloading torchmetrics-1.6.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (4.12.2)\n",
      "Collecting lightning-utilities>=0.10.0 (from pytorch_lightning)\n",
      "  Downloading lightning_utilities-0.11.9-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (3.11.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.10.0->pytorch_lightning) (75.1.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.16.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.1.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->pytorch_lightning) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.1.0->pytorch_lightning) (1.3.0)\n",
      "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics>=0.7.0->pytorch_lightning) (1.26.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.17.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (4.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.1.0->pytorch_lightning) (3.0.2)\n",
      "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (3.10)\n",
      "Downloading pytorch_lightning-2.4.0-py3-none-any.whl (815 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.2/815.2 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lightning_utilities-0.11.9-py3-none-any.whl (28 kB)\n",
      "Downloading torchmetrics-1.6.0-py3-none-any.whl (926 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m926.4/926.4 kB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: lightning-utilities, torchmetrics, pytorch_lightning\n",
      "Successfully installed lightning-utilities-0.11.9 pytorch_lightning-2.4.0 torchmetrics-1.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch_lightning"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
